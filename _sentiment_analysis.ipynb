{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e957e613",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Sivapriya\n",
      "[nltk_data]     S\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Sivapriya\n",
      "[nltk_data]     S\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Sivapriya\n",
      "[nltk_data]     S\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "import math\n",
    "import string   #used for various string operations\n",
    "import requests  #sending HTTP requests\n",
    "from bs4 import BeautifulSoup   #webscraping.extract information from HTML or XML files\n",
    "import re \n",
    "\n",
    "import os\n",
    "import sys\n",
    "from IPython.display import display, HTML\n",
    "import urllib  #URL encoding, decoding, fetching data from URLs\n",
    "\n",
    "import gzip  #compressing and decompressing data\n",
    "\n",
    "import nltk\n",
    "from nltk import tokenize  #text into individual words\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords  #insignificant words are removed\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "\n",
    "import pip\n",
    "#import theano\n",
    "import keras\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer,  text_to_word_sequence\n",
    "from keras import initializers as initializers, regularizers, constraints\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Embedding, Dropout, LSTM, GRU, Bidirectional, TimeDistributed\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "from keras.utils import plot_model, np_utils\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fbba1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Keras-Preprocessing in c:\\programdata\\anaconda3\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\sivapriya s\\appdata\\roaming\\python\\python39\\site-packages (from Keras-Preprocessing) (1.22.4)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from Keras-Preprocessing) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -5mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -4mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -3mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -2mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -1mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -0mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -5mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -4mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -3mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -2mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -1mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -0mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -5mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -4mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -3mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -2mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -1mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -0mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -5mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -4mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -3mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -2mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -1mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -0mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -5mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -4mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -3mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -2mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -1mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -0mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -5mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -4mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -3mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -2mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -1mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -0mpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install Keras-Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb2d01ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6c0c8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data=pd.read_csv('IMDB Dataset.csv')\n",
    "imdb_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe5b3fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Daniel Day-Lewis is the most versatile actor a...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>My guess would be this was originally going to...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Well, I like to watch bad horror B-Movies, cau...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>This IS the worst movie I have ever seen, as w...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>I have been a Mario fan for as long as I can r...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review sentiment\n",
       "0   One of the other reviewers has mentioned that ...  positive\n",
       "1   A wonderful little production. <br /><br />The...  positive\n",
       "2   I thought this was a wonderful way to spend ti...  positive\n",
       "3   Basically there's a family where a little boy ...  negative\n",
       "4   Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "..                                                ...       ...\n",
       "95  Daniel Day-Lewis is the most versatile actor a...  positive\n",
       "96  My guess would be this was originally going to...  negative\n",
       "97  Well, I like to watch bad horror B-Movies, cau...  negative\n",
       "98  This IS the worst movie I have ever seen, as w...  negative\n",
       "99  I have been a Mario fan for as long as I can r...  positive\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(imdb_data.shape)\n",
    "imdb_data.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b91a49e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.DataFrame(data=imdb_data,columns=['review',\"sentiment\"])\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2403c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "5  Probably my all-time favorite movie, a story o...  positive\n",
       "6  I sure would like to see a resurrection of a u...  positive\n",
       "7  This show was an amazing, fresh & innovative i...  negative\n",
       "8  Encouraged by the positive comments about this...  negative\n",
       "9  If you like original gut wrenching laughter yo...  positive"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f25e8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data.loc[:,'sentiment'] = pd.Categorical(imdb_data.sentiment)\n",
    "categoryToCode = dict( enumerate(imdb_data['sentiment'].cat.categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a255218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'negative', 1: 'positive'}\n"
     ]
    }
   ],
   "source": [
    "print(categoryToCode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73a753bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Daniel Day-Lewis is the most versatile actor a...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>My guess would be this was originally going to...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Well, I like to watch bad horror B-Movies, cau...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>This IS the worst movie I have ever seen, as w...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>I have been a Mario fan for as long as I can r...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review sentiment  overall\n",
       "0   One of the other reviewers has mentioned that ...  positive      1.0\n",
       "1   A wonderful little production. <br /><br />The...  positive      1.0\n",
       "2   I thought this was a wonderful way to spend ti...  positive      1.0\n",
       "3   Basically there's a family where a little boy ...  negative      0.0\n",
       "4   Petter Mattei's \"Love in the Time of Money\" is...  positive      1.0\n",
       "..                                                ...       ...      ...\n",
       "95  Daniel Day-Lewis is the most versatile actor a...  positive      1.0\n",
       "96  My guess would be this was originally going to...  negative      0.0\n",
       "97  Well, I like to watch bad horror B-Movies, cau...  negative      0.0\n",
       "98  This IS the worst movie I have ever seen, as w...  negative      0.0\n",
       "99  I have been a Mario fan for as long as I can r...  positive      1.0\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data_df\n",
    "df.loc[df['sentiment'] == 'positive', 'overall'] = 1\n",
    "df.loc[df['sentiment'] == 'negative', 'overall'] = 0\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb4472e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['sentiment']\n",
    "df.columns = ['Text','overall']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e543390a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  overall\n",
       "0  One of the other reviewers has mentioned that ...      1.0\n",
       "1  A wonderful little production. <br /><br />The...      1.0\n",
       "2  I thought this was a wonderful way to spend ti...      1.0\n",
       "3  Basically there's a family where a little boy ...      0.0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...      1.0\n",
       "5  Probably my all-time favorite movie, a story o...      1.0\n",
       "6  I sure would like to see a resurrection of a u...      1.0\n",
       "7  This show was an amazing, fresh & innovative i...      0.0\n",
       "8  Encouraged by the positive comments about this...      0.0\n",
       "9  If you like original gut wrenching laughter yo...      1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review=df\n",
    "df_review.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b53c8d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean String\n",
    "def cleanString(review,stopWords):\n",
    "    \"\"\"\n",
    "    Cleans input string using set rules.\n",
    "    Cleaning rules:         Every word is lemmatized and lowercased. Stopwords and non alpha-numeric words are removed.\n",
    "                            Each sentence ends with a period.\n",
    "    Input:   review       - string(in sentence structure)\n",
    "             stopWords    - set of strings which should be removed from review\n",
    "    Output:  returnString - cleaned input string\n",
    "             idx_list     - list of lists, one list is equal to one sentence. In every list are the index\n",
    "                            of each word as they appeared in the non cleaned sentence\n",
    "                            e.g. nonCleaned = \"This is a test.\" -> cleaned = \"This test.\" -> cleaned_index = [[0,3]]\n",
    "    \"\"\"\n",
    "    # Init the Wordnet Lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    returnString = \"\"\n",
    "    sentence_token = tokenize.sent_tokenize(review)\n",
    "    idx_list = []\n",
    "    for j in range(len(sentence_token)):\n",
    "        single_sentence = tokenize.word_tokenize(sentence_token[j])\n",
    "        sentences_filtered = [(idx,lemmatizer.lemmatize(w.lower())) for idx,w in enumerate(single_sentence) \n",
    "                              if w.lower() not in stopWords and w.isalnum()]\n",
    "        idx_list.append([x[0] for x in sentences_filtered])\n",
    "        word_list = [x[1] for x in sentences_filtered]\n",
    "        returnString = returnString + ' '.join(word_list) + ' . '\n",
    "    \n",
    "    return returnString, idx_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcd36850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 of 50000 articles cleaned.\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewer mentioned watching 1 oz episode h...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production . br br filming te...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically family little boy jake think zombie ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei love time money visually stunnin...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  overall\n",
       "0  one reviewer mentioned watching 1 oz episode h...      1.0\n",
       "1  wonderful little production . br br filming te...      1.0\n",
       "2  thought wonderful way spend time hot summer we...      1.0\n",
       "3  basically family little boy jake think zombie ...      0.0\n",
       "4  petter mattei love time money visually stunnin...      1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Cleans raw data using the cleanString() function from above.\n",
    "English stopwords are used from nltk library.\n",
    "Cleaned dataset is saved in 'data_cleaned' pandas dataframe.\n",
    "Labels are converted to numbers,\n",
    "\"\"\"\n",
    "articles = []\n",
    "n = data_df['Text'].shape[0]\n",
    "col_number = data_df.columns.get_loc('Text')\n",
    "stopWords = set(stopwords.words('english'))\n",
    "data_cleaned = data_df.copy()\n",
    "for i in range(n):\n",
    "    temp_string,idx_string = cleanString(data_df.iloc[i,col_number],stopWords)\n",
    "    articles.append(temp_string)\n",
    "    print(str(i+1)+' of '+str(n)+\" articles cleaned.\",end='\\r')\n",
    "    \n",
    "data_cleaned.loc[:,'Text'] = pd.Series(articles,index=data_df.index)\n",
    "#data_cleaned.loc[:,'Category'] = pd.Categorical(data_cleaned.Category)\n",
    "#data_cleaned['Code'] = data_cleaned.Category.cat.codes\n",
    "#categoryToCode = dict( enumerate(data_cleaned['Category'].cat.categories))\n",
    "\n",
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2907bc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 200000 # maximum number of unique words that should be included in the tokenized word index\n",
    "MAX_SENTENCE_NUM = 40 # maximum number of sentences in one document\n",
    "MAX_WORD_NUM = 50     # maximum number of words in each sentence\n",
    "EMBED_SIZE = 100      # vector size of word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "884aee00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:10: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "<>:10: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "C:\\Users\\SIVAPR~1\\AppData\\Local\\Temp/ipykernel_1212/2429561682.py:10: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  s = ' '.join([word.strip(string.punctuation) for word in s.split() if word.strip(string.punctuation) is not \"\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 89187\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Using the keras Tokenizer class a word index is built.\n",
    "The most 'MAX_FEATURES' used words are tokenized to a number.\n",
    "this dictionary is saved in word_index\n",
    "\"\"\"\n",
    "texts = []\n",
    "n = data_cleaned['Text'].shape[0]\n",
    "for i in range(n):\n",
    "    s = data_cleaned['Text'].iloc[i]\n",
    "    s = ' '.join([word.strip(string.punctuation) for word in s.split() if word.strip(string.punctuation) is not \"\"])\n",
    "    texts.append(s)\n",
    "tokenizer = Tokenizer(num_words=MAX_FEATURES,lower=True, oov_token=None)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "print('Number of tokens: ' + str(len(word_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "393be0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewer mentioned watching 1 oz episode h...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production . br br filming te...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically family little boy jake think zombie ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei love time money visually stunnin...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  overall\n",
       "0  one reviewer mentioned watching 1 oz episode h...      1.0\n",
       "1  wonderful little production . br br filming te...      1.0\n",
       "2  thought wonderful way spend time hot summer we...      1.0\n",
       "3  basically family little boy jake think zombie ...      0.0\n",
       "4  petter mattei love time money visually stunnin...      1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8dfbfe89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='IMDB Dataset.csv' mode='r' encoding='utf8'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open(os.path.join('IMDB Dataset.csv'), encoding='utf8')\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7d1ed82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "embeddings_index = {}  # Dictionary to store word embeddings\n",
    "\n",
    "with open('IMDB Dataset.csv', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        if len(values) < 2:\n",
    "            continue  # Skip lines with insufficient values\n",
    "        word = values[0]\n",
    "        try:\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "        except ValueError:\n",
    "            continue  # Skip lines with non-numeric values\n",
    "\n",
    "df = pd.DataFrame.from_dict(embeddings_index, orient='index', columns=['embedding_matrix'])\n",
    "df.index.name = 'word'\n",
    "df.reset_index(inplace=True)\n",
    "df['embedding_matrix'] = df['embedding_matrix'].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2aa888b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 word vectors.\n"
     ]
    }
   ],
   "source": [
    "print('Found %s word vectors.' % len(embeddings_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15a202fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total absent words are 44038 which is 49.38 % of total words\n",
      "Words with 2 or less mentions 45149 which is 50.62 % of total words\n",
      "0 words to proceed.\n"
     ]
    }
   ],
   "source": [
    "EMBED_SIZE = 100\n",
    "\n",
    "min_wordCount = 2\n",
    "absent_words = 0\n",
    "small_words = 0\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBED_SIZE))\n",
    "word_counts = tokenizer.word_counts\n",
    "for word, i in word_index.items():\n",
    "    if word_counts[word] > min_wordCount:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "        else:\n",
    "            absent_words += 1\n",
    "    else:\n",
    "        small_words += 1\n",
    "print('Total absent words are', absent_words, 'which is', \"%0.2f\" % (absent_words * 100 / len(word_index)),\n",
    "      '% of total words')\n",
    "print('Words with '+str(min_wordCount)+' or less mentions', small_words, 'which is', \"%0.2f\" % (small_words * 100 / len(word_index)),\n",
    "      '% of total words')\n",
    "print(str(len(word_index)-small_words-absent_words) + ' words to proceed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35a46022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[word_index['great']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8068c7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df(dataframe, column_name, training_split, validation_split, test_split):\n",
    "    \"\"\"\n",
    "    Splits a pandas dataframe into trainingset, validationset and testset in specified ratio.\n",
    "    All sets are balanced, which means they have the same ratio for each category as the full set.\n",
    "    Input:   dataframe        - Pandas Dataframe, should include a column for data and one for categories\n",
    "             column_name      - Name of dataframe column which contains the categorical output values\n",
    "             training_split   - from ]0,1[, default = 0.6\n",
    "             validation_split - from ]0,1[, default = 0.2        \n",
    "             test_split       - from ]0,1[, default = 0.2\n",
    "                                Sum of all splits need to be 1\n",
    "    Output:  train            - Pandas DataFrame of trainset\n",
    "             validation       - Pandas DataFrame of validationset\n",
    "             test             - Pandas DataFrame of testset\n",
    "    \"\"\"\n",
    "    if training_split + validation_split + test_split != 1.0:\n",
    "        raise ValueError('Split paramter sum should be 1.0')\n",
    "        \n",
    "    total = len(dataframe.index)\n",
    " \n",
    "    train = dataframe.reset_index().groupby(column_name).apply(lambda x: x.sample(frac=training_split))\\\n",
    "    .reset_index(drop=True).set_index('index')\n",
    "    train = train.sample(frac=1)\n",
    "    temp_df = dataframe.drop(train.index)\n",
    "    validation = temp_df.reset_index().groupby(column_name)\\\n",
    "    .apply(lambda x: x.sample(frac=validation_split/(test_split+validation_split)))\\\n",
    "           .reset_index(drop=True).set_index('index')\n",
    "    validation = validation.sample(frac=1)\n",
    "    test = temp_df.drop(validation.index)\n",
    "    test = test.sample(frac=1)\n",
    "    \n",
    "    print('Total: ', len(dataframe))\n",
    "    print('Training: ', len(train), ', Percentage: ', len(train)/len(dataframe))\n",
    "    print('Validation: ', len(validation), ', Percentage: ', len(validation)/len(dataframe))\n",
    "    print('Test:', len(test), ', Percentage: ', len(test)/len(dataframe))\n",
    "\n",
    "    return train, validation, test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5ca03c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLayer(Layer):\n",
    "    \"\"\"\n",
    "    Hierarchial Attention Layer as described by Hierarchical Attention Networks for Document Classification(2016)\n",
    "    - Yang et. al.\n",
    "    Source: https://www.cs.cmu.edu/~hovy/papers/16HLT-hierarchical-attention-networks.pdf\n",
    "    Theano backend\n",
    "    \"\"\"\n",
    "    def __init__(self,attention_dim=100,return_coefficients=False,**kwargs):\n",
    "        # Initializer \n",
    "        self.supports_masking = True\n",
    "        self.return_coefficients = return_coefficients\n",
    "        self.init = initializers.get('glorot_uniform') # initializes values with uniform distribution\n",
    "        self.attention_dim = attention_dim\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Builds all weights\n",
    "        # W = Weight matrix, b = bias vector, u = context vector\n",
    "        assert len(input_shape) == 3\n",
    "        self.W = K.variable(self.init((input_shape[-1], self.attention_dim)),name='W')\n",
    "        self.b = K.variable(self.init((self.attention_dim, )),name='b')\n",
    "        self.u = K.variable(self.init((self.attention_dim, 1)),name='u')\n",
    "        set_trainable_weights = [self.W, self.b, self.u]\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, hit, mask=None):\n",
    "        # Here, the actual calculation is done\n",
    "        uit = K.bias_add(K.dot(hit, self.W),self.b)\n",
    "        uit = K.tanh(uit)\n",
    "        \n",
    "        ait = K.dot(uit, self.u)\n",
    "        ait = K.squeeze(ait, -1)\n",
    "        ait = K.exp(ait)\n",
    "        \n",
    "        if mask is not None:\n",
    "            ait *= K.cast(mask, K.floatx())\n",
    "\n",
    "        ait /= K.cast(K.sum(ait, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "        ait = K.expand_dims(ait)\n",
    "        weighted_input = hit * ait\n",
    "        \n",
    "        if self.return_coefficients:\n",
    "            return [K.sum(weighted_input, axis=1), ait]\n",
    "        else:\n",
    "            return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.return_coefficients:\n",
    "            return [(input_shape[0], input_shape[-1]), (input_shape[0], input_shape[-1], 1)]\n",
    "        else:\n",
    "            return input_shape[0], input_shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c76ba4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\initializers\\initializers.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " word_input (InputLayer)     [(None, 50)]              0         \n",
      "                                                                 \n",
      " word_embedding (Embedding)  (None, 50, 100)           8918800   \n",
      "                                                                 \n",
      " word_gru (Bidirectional)    (None, 50, 100)           45600     \n",
      "                                                                 \n",
      " word_dense (Dense)          (None, 50, 100)           10100     \n",
      "                                                                 \n",
      " word_attention (AttentionLa  [(None, 100),            10200     \n",
      " yer)                         (None, 50, 1)]                     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,984,700\n",
      "Trainable params: 65,900\n",
      "Non-trainable params: 8,918,800\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sent_input (InputLayer)     [(None, 40, 50)]          0         \n",
      "                                                                 \n",
      " sent_linking (TimeDistribut  (None, 40, 100)          8984700   \n",
      " ed)                                                             \n",
      "                                                                 \n",
      " sent_gru (Bidirectional)    (None, 40, 100)           45600     \n",
      "                                                                 \n",
      " sent_dense (Dense)          (None, 40, 100)           10100     \n",
      "                                                                 \n",
      " sent_attention (AttentionLa  [(None, 100),            10200     \n",
      " yer)                         (None, 40, 1)]                     \n",
      "                                                                 \n",
      " sent_dropout (Dropout)      (None, 100)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,050,802\n",
      "Trainable params: 132,002\n",
      "Non-trainable params: 8,918,800\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create Keras functional model for hierarchical attention network\n",
    "\"\"\"\n",
    "embedding_layer = Embedding(len(word_index) + 1,EMBED_SIZE,weights=[embedding_matrix], \n",
    "                            input_length=MAX_WORD_NUM, trainable=False,name='word_embedding')\n",
    "\n",
    "# Words level attention model\n",
    "word_input = Input(shape=(MAX_WORD_NUM,), dtype='int32',name='word_input')\n",
    "word_sequences = embedding_layer(word_input)\n",
    "word_gru = Bidirectional(GRU(50, return_sequences=True),name='word_gru')(word_sequences)\n",
    "word_dense = Dense(100, activation='relu', name='word_dense')(word_gru) \n",
    "word_att,word_coeffs = AttentionLayer(EMBED_SIZE,True,name='word_attention')(word_dense)\n",
    "wordEncoder = Model(inputs = word_input,outputs = word_att)\n",
    "\n",
    "# Sentence level attention model\n",
    "sent_input = Input(shape=(MAX_SENTENCE_NUM,MAX_WORD_NUM), dtype='int32',name='sent_input')\n",
    "sent_encoder = TimeDistributed(wordEncoder,name='sent_linking')(sent_input)\n",
    "sent_gru = Bidirectional(GRU(50, return_sequences=True),name='sent_gru')(sent_encoder)\n",
    "sent_dense = Dense(100, activation='relu', name='sent_dense')(sent_gru) \n",
    "sent_att,sent_coeffs = AttentionLayer(EMBED_SIZE,return_coefficients=True,name='sent_attention')(sent_dense)\n",
    "sent_drop = Dropout(0.5,name='sent_dropout')(sent_att)\n",
    "preds = Dense(2, activation='softmax',name='output')(sent_drop)\n",
    "\n",
    "# Model compile\n",
    "model = Model(sent_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['acc'])\n",
    "print(wordEncoder.summary())\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "856cc469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorical(series,class_dict):\n",
    "    \"\"\"\n",
    "    Converts category labels to vectors,\n",
    "    Input:     series     - pandas Series containing numbered category labels\n",
    "               class_dict - dictionary of integer to category string \n",
    "                            e.g. {0: 'business', 1: 'entertainment', 2: 'politics', 3: 'sport', 4: 'tech'}\n",
    "    Output:    Array      - numpy array containing categories converted to lists\n",
    "                            e.g. 0:'business'      -> [1 0 0 0 0]\n",
    "                                 1:'entertainment' -> [0 1 0 0 0]\n",
    "                                 2:'politics'      -> [0 0 1 0 0]\n",
    "                                 3:'sport'         -> [0 0 0 1 0]\n",
    "                                 4:'tech'          -> [0 0 0 0 1]\n",
    "    \"\"\"\n",
    "    n_classes = len(class_dict)\n",
    "    new_dict = {}\n",
    "    for key,value in class_dict.items():\n",
    "        cat_list = [0] * n_classes\n",
    "        cat_list[key] = 1\n",
    "        new_dict[key] = cat_list\n",
    "    y_cat = []\n",
    "    for key,value in series.iteritems():\n",
    "        y_cat.append(new_dict[value])\n",
    "    return np.array(y_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2bac3410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordToSeq(text,word_index,max_sentences,max_words,max_features):\n",
    "    \"\"\"\n",
    "    Converts a string to a numpy matrix where each word is tokenized.\n",
    "    Arrays are zero-padded to max_sentences and max_words length.\n",
    "    \n",
    "    Input:    text           - string of sentences\n",
    "              word_index     - trained word_index\n",
    "              max_sentences  - maximum number of sentences allowed per document for HAN\n",
    "              max_words      - maximum number of words in each sentence for HAN\n",
    "              max_features   - maximum number of unique words to be tokenized\n",
    "    Output:   data           - Numpy Matrix of size [max_sentences x max_words]\n",
    "    \"\"\"\n",
    "    sentences = tokenize.sent_tokenize(text)\n",
    "    data = np.zeros((max_sentences, max_words), dtype='int32')\n",
    "    for j, sent in enumerate(sentences):\n",
    "        if j< max_sentences:\n",
    "            wordTokens = tokenize.word_tokenize(sent.rstrip('.'))\n",
    "            wordTokens = [w for w in wordTokens]\n",
    "            k=0\n",
    "            for _, word in enumerate(wordTokens):\n",
    "                try:\n",
    "                    if k<max_words and word_index[word]<max_features:\n",
    "                        data[j,k] = word_index[word]\n",
    "                        k=k+1\n",
    "                except:\n",
    "                    pass\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34107900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total:  50000\n",
      "Training:  40000 , Percentage:  0.8\n",
      "Validation:  5000 , Percentage:  0.1\n",
      "Test: 5000 , Percentage:  0.1\n"
     ]
    }
   ],
   "source": [
    "train, validation, test = split_df(data_cleaned, 'overall',0.8,0.1,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cfc52aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "paras = []\n",
    "for i in range(train['Text'].shape[0]):\n",
    "    sequence = wordToSeq(train['Text'].iloc[i],word_index,MAX_SENTENCE_NUM,MAX_WORD_NUM,MAX_FEATURES)\n",
    "    paras.append(sequence)\n",
    "x_train = np.array(paras)\n",
    "y_train = to_categorical(train['overall'],categoryToCode)\n",
    "\n",
    "#Validation\n",
    "paras = []\n",
    "for i in range(validation['Text'].shape[0]):\n",
    "    sequence = wordToSeq(validation['Text'].iloc[i],word_index,MAX_SENTENCE_NUM,MAX_WORD_NUM,MAX_FEATURES)\n",
    "    paras.append(sequence)\n",
    "x_val = np.array(paras)\n",
    "y_val = to_categorical(validation['overall'],categoryToCode)\n",
    "\n",
    "#Test\n",
    "paras = []\n",
    "for i in range(test['Text'].shape[0]):\n",
    "    sequence = wordToSeq(test['Text'].iloc[i],word_index,MAX_SENTENCE_NUM,MAX_WORD_NUM,MAX_FEATURES)\n",
    "    paras.append(sequence)\n",
    "x_test = np.array(paras)\n",
    "y_test = to_categorical(test['overall'],categoryToCode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5db5e90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "1250/1250 [==============================] - 984s 774ms/step - loss: 0.6932 - acc: 0.4997 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 2/7\n",
      "1250/1250 [==============================] - 772s 618ms/step - loss: 0.6932 - acc: 0.4985 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 3/7\n",
      "1250/1250 [==============================] - 739s 591ms/step - loss: 0.6932 - acc: 0.5011 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 4/7\n",
      "1250/1250 [==============================] - 635s 508ms/step - loss: 0.6932 - acc: 0.5001 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 5/7\n",
      "1250/1250 [==============================] - 711s 569ms/step - loss: 0.6932 - acc: 0.4990 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 6/7\n",
      "1250/1250 [==============================] - 702s 561ms/step - loss: 0.6932 - acc: 0.5006 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 7/7\n",
      "1250/1250 [==============================] - 714s 571ms/step - loss: 0.6932 - acc: 0.4985 - val_loss: 0.6932 - val_acc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=7, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad02c3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 33s 213ms/step - loss: 0.6932 - acc: 0.5000\n",
      "Test set accuracy:  0.5\n",
      "Test set loss:  0.6932233572006226\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test,y_test)\n",
    "print(\"Test set accuracy: \",acc)\n",
    "print(\"Test set loss: \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e00601fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Saves the model in a hdf5 file\n",
    "model.save('C:/project/Python/Sentiment Analysis/Model_7epoch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48c6cabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 33s 211ms/step - loss: 0.6932 - acc: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6932233572006226, 0.5]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=x_test, y=y_test, batch_size=None, verbose=1, sample_weight=None, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c1240fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7639  5560     3 ...     0     0     0]\n",
      " [   56 24810 50800 ...     0     0     0]\n",
      " [ 3232  3759    42 ...     0     0     0]\n",
      " ...\n",
      " [    0     0     0 ...     0     0     0]\n",
      " [    0     0     0 ...     0     0     0]\n",
      " [    0     0     0 ...     0     0     0]] [1 0]\n"
     ]
    }
   ],
   "source": [
    "print(x_test[5],y_test[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294dbfc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
